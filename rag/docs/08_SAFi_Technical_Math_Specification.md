---
title: SAFi Explained: The Formal Mathematical Specification
slug: technical-math-specification
tags: ["safi", "reference", "math", "specification"]
summary: Formal mathematical and technical specification for SAFi: objects, timing, data flow, pseudocode, and Spirit formulas.
version: 1.0
---

# SAFi Explained: The Formal Mathematical Specification

## Purpose
This document provides the formal specification for the Self Alignment Framework Interface (SAFi). It defines the objects, data flow, timing model, formulas, and pseudocode used to implement the system. It complements the conceptual documents by acting as the engineering blueprint.

## Core mathematical objects
The main objects are:

- t: the discrete interaction index or turn number  
- x_t: the input context from the user  
- V = {(v_i, w_i)}: the declared set of values with weights that sum to 1  
- a_t: the draft answer generated by the Intellect  
- D_t: the Will’s gate decision, approve or violation  
- E_t: the Will’s explanation for its decision  
- L_t: the Conscience ledger, a record of scores and confidences  
- S_t: the Spirit’s coherence score for the turn  
- M_t: the system’s memory of prior audits and aggregates  

## System architecture and data flow
SAFi uses a hybrid timing model.

### Synchronous
The Intellect and Will run synchronously. The user does not see a reply until the Will issues its decision.

### Asynchronous
The Conscience and Spirit run asynchronously in the background. They audit the response after the user has received it.

### Data flow for an approved response
The synchronous chain is Intellect → Will → User.  
The asynchronous chain is Conscience → Spirit → Memory update.

## Pseudocode for the SAFi loop
```python
# Synchronous path
draft, reflection = Intellect(prompt, values, memory)
decision, reason = Will(draft, prompt, values, reflection)

if decision == "violation":
    return safe_reply(reason)
    log_event(prompt, draft, decision, reason)
else:
    return draft
    enqueue_audit_job(prompt, draft, values, memory)

# Asynchronous audit
def run_audit(job):
    ledger = Conscience(job.draft, job.prompt, job.values)
    spirit_score = calculate_spirit_score(ledger, job.values)
    projection = create_projection_vector(ledger, job.values)
    new_memory = update_memory_vector(job.memory.mu, projection)
    drift = calculate_drift(projection, job.memory.mu)

    store_audit_results(ledger, spirit_score, drift)
    update_system_memory(new_memory)

    if spirit_score < alert_threshold or drift > drift_threshold:
        raise_alert(reasons=get_offending_values(ledger))
